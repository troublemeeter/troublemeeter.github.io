<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>æœºå™¨å­¦ä¹ é¢è¯•çŸ¥è¯†ç‚¹æ€»ç»“</title>
    <url>/ml-overview/</url>
    <content><![CDATA[<p>å¯¹é¢è¯•ä¸­æœºå™¨å­¦ä¹ æ¨¡å‹å¸¸ç¢°åˆ°çš„é—®é¢˜è¿›è¡Œæ€»ç»“å¯¹æ¯”ã€‚</p>
<a id="more"></a>

<h2 id="æ¨¡å‹æ±‡æ€»"><a href="#æ¨¡å‹æ±‡æ€»" class="headerlink" title="æ¨¡å‹æ±‡æ€»"></a>æ¨¡å‹æ±‡æ€»</h2><ol>
<li><h3 id="Decision-Tree"><a href="#Decision-Tree" class="headerlink" title="Decision Tree"></a>Decision Tree</h3><ol>
<li><h4 id="ID3"><a href="#ID3" class="headerlink" title="ID3"></a>ID3</h4> å¤šå‰æ ‘ï¼šæŒ‰é€‰æ‹©çš„ç‰¹å¾ä¸ªæ•°åˆ†å‰;<br> ä¿¡æ¯å¢ç›Šï¼šmaxï¼ˆAï¼‰ï¼šI(D,A) = H(D) - H(D|A);<br> æ— æ³•å¤„ç†è¿ç»­ç‰¹å¾;<br> ä¿¡æ¯å¢ç›Šå€¾å‘äºé€‰æ‹©ç‰¹å¾ä¸ªæ•°å¤šçš„ç‰¹å¾;<br> æ— æ³•å¤„ç†ç¼ºå¤±å€¼;<br> æ²¡è€ƒè™‘è¿‡æ‹Ÿåˆ;<br> ä¸æ”¯æŒç¼ºå¤±å€¼å¤„ç†;</li>
<li><h4 id="C4-5"><a href="#C4-5" class="headerlink" title="C4.5"></a>C4.5</h4> å¤šå‰æ ‘ï¼Œè¿ç»­èŠ‚ç‚¹å¤„ä¸ºäºŒå‰æ ‘;<br> ä¿¡æ¯å¢ç›Šæ¯”;<br> å‰ªæï¼šé¢„å‰ªæï¼Œåå‰ªæ;<br> åªèƒ½ç”¨äºåˆ†ç±»;<br> æ”¯æŒç¼ºå¤±å€¼å¤„ç†;</li>
<li><h4 id="cart"><a href="#cart" class="headerlink" title="cart"></a>cart</h4> äºŒå‰æ ‘ï¼Œæ”¯æŒç¼ºå¤±å€¼å¤„ç†;<br> åˆ†ç±»ï¼šginiç³»æ•°;<br> å›å½’ï¼šå‡æ–¹å·®;</li>
</ol>
</li>
<li><h3 id="Boostï¼ˆæ”¹å˜æ ·æœ¬åˆ†å¸ƒï¼‰"><a href="#Boostï¼ˆæ”¹å˜æ ·æœ¬åˆ†å¸ƒï¼‰" class="headerlink" title="Boostï¼ˆæ”¹å˜æ ·æœ¬åˆ†å¸ƒï¼‰"></a>Boostï¼ˆæ”¹å˜æ ·æœ¬åˆ†å¸ƒï¼‰</h3><ol>
<li><h4 id="Adaboost"><a href="#Adaboost" class="headerlink" title="Adaboost"></a>Adaboost</h4><ul>
<li>åˆ†ç±»ï¼š<ul>
<li>æŒ‡æ•°æŸå¤±å‡½æ•° + åŠ æ³•æ¨¡å‹ + å‰å‘åˆ†æ­¥ç®—æ³•</li>
<li>æ ¹æ®å½“å‰çš„å­¦ä¹ è¯¯å·®ç‡æ›´æ–°è®­ç»ƒæ ·æœ¬çš„æƒé‡</li>
<li>æ ·æœ¬æƒé‡w-&gt;åˆ†ç±»å™¨æ ·æœ¬è¯¯å·®ç‡e-&gt;åˆ†ç±»å™¨æƒé‡Î±-&gt;æ ·æœ¬æƒé‡wï¼ˆå’Œå‰ä¸€ä¸ªæ€»åˆ†ç±»å™¨æœ‰å…³ï¼‰</li>
</ul>
</li>
<li>å›å½’ï¼š<ul>
<li>å¹³æ–¹æŸå¤±å‡½æ•°ï¼Œæ‹Ÿåˆæ®‹å·®</li>
<li>æ ¹æ®åˆ’åˆ†åŒºåŸŸï¼Œæœç´¢ä½¿å¾—æŸå¤±å‡½æ•°æœ€å°çš„å–å€¼ </li>
</ul>
</li>
<li>å¼±å­¦ä¹ å™¨ä¸å›ºå®šï¼›å¯¹å¼‚å¸¸ç‚¹æ•æ„Ÿï¼Œæ ·æœ¬æƒé‡è¾ƒé«˜ï¼›ç²¾åº¦é«˜  </li>
</ul>
</li>
<li><h4 id="GBDT"><a href="#GBDT" class="headerlink" title="GBDT"></a>GBDT</h4><p> å¼±å­¦ä¹ å™¨å›ºå®šä¸ºcartæ ‘;<br> æŸå¤±å‡½æ•°ä¸å›ºå®š;<br> æ‹ŸåˆæŸå¤±å‡½æ•°çš„è´Ÿæ¢¯åº¦;<br> åˆ†ç±»ï¼šå¯¹æ•°ä¼¼ç„¶æŸå¤±å‡½æ•°ï¼ˆæŒ‡æ•°æŸå¤±å˜ä¸ºadaboostï¼‰;<br> å›å½’ï¼šå‡æ–¹å·®ï¼Œç»å¯¹æŸå¤±;<br> é‡‡æ ·æ˜¯ä¸æ”¾å›é‡‡æ ·; </p>
<pre><code>Qï¼šæ€æ ·è®¾ç½®å•æ£µæ ‘çš„åœæ­¢ç”Ÿé•¿æ¡ä»¶ï¼Ÿ  
Aï¼šèŠ‚ç‚¹åˆ†è£‚æ—¶çš„æœ€å°æ ·æœ¬æ•°ï¼Œæœ€å¤§æ·±åº¦ï¼Œæœ€å¤šå¶å­èŠ‚ç‚¹æ•°ï¼Œlossæ»¡è¶³çº¦æŸæ¡ä»¶  

Qï¼šè¯„ä¼°ç‰¹å¾çš„æƒé‡å¤§å°  
Aï¼š  
1. é€šè¿‡è®¡ç®—æ¯ä¸ªç‰¹å¾åœ¨è®­ç»ƒé›†ä¸‹çš„ä¿¡æ¯å¢ç›Šï¼Œæœ€åè®¡ç®—æ¯ä¸ªç‰¹å¾ä¿¡æ¯å¢ç›Šä¸æ‰€æœ‰ç‰¹å¾ä¿¡æ¯å¢ç›Šä¹‹å’Œçš„æ¯”ä¾‹ä¸ºæƒé‡å€¼ï¼›  
2. å€Ÿé‰´æŠ•ç¥¨æœºåˆ¶ã€‚ç”¨ç›¸åŒçš„gbdtå‚æ•°å¯¹wæ¯ä¸ªç‰¹å¾è®­ç»ƒå‡ºä¸€ä¸ªæ¨¡å‹ï¼Œç„¶ååœ¨è¯¥æ¨¡å‹ä¸‹è®¡ç®—æ¯ä¸ªç‰¹å¾æ­£ç¡®åˆ†ç±»çš„ä¸ªæ•°ï¼Œæœ€åè®¡ç®—æ¯ä¸ªç‰¹å¾æ­£ç¡®åˆ†ç±»çš„ä¸ªæ•°ä¸æ‰€æœ‰æ­£ç¡®åˆ†ç±»ä¸ªæ•°ä¹‹å’Œçš„æ¯”ä¾‹ä¸ºæƒé‡å€¼ã€‚  

Qï¼šå¢åŠ æ ·æœ¬æ•°é‡æ—¶ï¼Œè®­ç»ƒæ—¶é•¿æ˜¯çº¿æ€§å¢åŠ å—ï¼Ÿ  
Aï¼šä¸æ˜¯ã€‚å› ä¸ºç”Ÿæˆå•æ£µå†³ç­–æ ‘æ—¶ï¼ŒæŸå¤±å‡½æ•°æå°å€¼ä¸æ ·æœ¬æ•°é‡Nä¸æ˜¯çº¿æ€§ç›¸å…³  ï¼Ÿï¼Ÿï¼Ÿ  

Qï¼šå¢åŠ æ ‘çš„æ£µæ ‘æ—¶ï¼Œè®­ç»ƒæ—¶é•¿æ˜¯çº¿æ€§å¢åŠ å—ï¼Ÿ  
Aï¼šä¸æ˜¯ã€‚å› ä¸ºæ¯æ£µæ ‘çš„ç”Ÿæˆçš„æ—¶é—´å¤æ‚åº¦ä¸ä¸€æ ·ã€‚   

Qï¼šå¦‚ä½•é˜²æ­¢è¿‡æ‹Ÿåˆ  
Aï¼š  
1. å¢åŠ æ ·æœ¬ï¼ˆdata bias or small dataçš„ç¼˜æ•…ï¼‰ï¼Œç§»é™¤å™ªå£°ã€‚  
2. å‡å°‘ç‰¹å¾ï¼Œä¿ç•™é‡è¦çš„ç‰¹å¾ï¼ˆå¯ä»¥ç”¨PCAç­‰å¯¹ç‰¹å¾è¿›è¡Œé™ç»´ï¼‰ã€‚  
3. å¯¹æ ·æœ¬è¿›è¡Œé‡‡æ ·ï¼ˆç±»ä¼¼baggingï¼‰ã€‚å°±æ˜¯å»ºæ ‘çš„æ—¶å€™ï¼Œä¸æ˜¯æŠŠæ‰€æœ‰çš„æ ·æœ¬éƒ½ä½œä¸ºè¾“å…¥ï¼Œè€Œæ˜¯é€‰æ‹©ä¸€ä¸ªå­é›†ã€‚  
4. å¯¹ç‰¹å¾è¿›è¡Œé‡‡æ ·ã€‚ç±»ä¼¼æ ·æœ¬é‡‡æ ·ä¸€æ ·,æ¯æ¬¡å»ºæ ‘çš„æ—¶å€™ï¼Œåªå¯¹éƒ¨åˆ†çš„ç‰¹å¾è¿›è¡Œåˆ‡åˆ†ã€‚  
5. åŠ æ­£åˆ™é¡¹ï¼Œå‰ªæ  

Qï¼šgbdtåœ¨è®­ç»ƒå’Œé¢„æµ‹çš„æ—¶å€™éƒ½ç”¨åˆ°äº†æ­¥é•¿ï¼Œè¿™ä¸¤ä¸ªæ­¥é•¿ä¸€æ ·ä¹ˆï¼Ÿ  
Aï¼šä¸€æ ·ã€‚ ï¼Ÿï¼Ÿï¼Ÿ  

Qï¼šgbdtä¸­å“ªäº›éƒ¨åˆ†å¯ä»¥å¹¶è¡Œï¼Ÿ  
Aï¼š  
1. è®¡ç®—æ¯ä¸ªæ ·æœ¬çš„è´Ÿæ¢¯åº¦  
2. åˆ†è£‚æŒ‘é€‰æœ€ä½³ç‰¹å¾åŠå…¶åˆ†å‰²ç‚¹æ—¶ï¼Œå¯¹ç‰¹å¾è®¡ç®—ç›¸åº”çš„è¯¯å·®åŠå‡å€¼æ—¶  
3. æ›´æ–°æ¯ä¸ªæ ·æœ¬çš„è´Ÿæ¢¯åº¦æ—¶  
4. æœ€åé¢„æµ‹è¿‡ç¨‹ä¸­ï¼Œæ¯ä¸ªæ ·æœ¬å°†ä¹‹å‰çš„æ‰€æœ‰æ ‘çš„ç»“æœç´¯åŠ çš„æ—¶å€™  </code></pre></li>
<li><h3 id="xgboost"><a href="#xgboost" class="headerlink" title="xgboost"></a>xgboost</h3></li>
</ol>
</li>
<li><h3 id="å›¾æ¨¡å‹"><a href="#å›¾æ¨¡å‹" class="headerlink" title="å›¾æ¨¡å‹"></a>å›¾æ¨¡å‹</h3><ol>
<li><h4 id="HMM"><a href="#HMM" class="headerlink" title="HMM"></a>HMM</h4><ul>
<li>ä¸¤ä¸ªå‡è®¾ï¼š<ul>
<li>é½æ¬¡é©¬å°”ç§‘å¤«é“¾å‡è®¾ï¼š<br>éšè—çŠ¶æ€ä¹‹å’Œä¹‹å‰çš„ä¸€ä¸ªæœ‰å…³</li>
<li>è§‚æµ‹ç‹¬ç«‹å‡è®¾ï¼š<br>è§‚æµ‹çŠ¶æ€ä¹‹å’Œå½“å‰çš„éšè—çŠ¶æ€æœ‰å…³</li>
</ul>
</li>
<li>ä¸‰ä¸ªé—®é¢˜ï¼š<ul>
<li>å·²çŸ¥å‚æ•°ï¼Œè§‚æµ‹åºåˆ—ï¼Œæ±‚è§‚æµ‹åºåˆ—æ¦‚ç‡ï¼Œå‰å‘åå‘ç®—æ³•</li>
<li>å·²çŸ¥è§‚æµ‹åºåˆ—ï¼Œä¼°è®¡æ¨¡å‹å‚æ•°ï¼ŒEMç®—æ³•</li>
<li>å·²çŸ¥å‚æ•°ï¼Œè§‚æµ‹åºåˆ—ï¼Œæ¨æµ‹çŠ¶æ€åºåˆ—ï¼Œç»´ç‰¹æ¯”ç®—æ³•</li>
</ul>
</li>
</ul>
</li>
<li><h3 id="CRF"><a href="#CRF" class="headerlink" title="CRF"></a>CRF</h3><p> å‚æ•°ä¼°è®¡ï¼Œæå¤§ä¼¼ç„¶ä¼°è®¡<br> æ¨æµ‹çŠ¶æ€åºåˆ—ï¼Œç»´ç‰¹æ¯”ç®—æ³•<br> ç‰¹å¾å‡½æ•°è®¾è®¡</p>
<p>HMM    ç”Ÿæˆæ¨¡å‹ï¼Œé©¬å°”å¯å¤«å‡è®¾<br>CRF åˆ¤åˆ«æ¨¡å‹ï¼Œæ²¡æœ‰é©¬å°”å¯å¤«å‡è®¾ï¼ˆæ‰€ä»¥å®¹æ˜“æ›´å¥½çš„é‡‡çº³ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼‰</p>
</li>
</ol>
</li>
</ol>
<h2 id="æ¨¡å‹å¯¹æ¯”"><a href="#æ¨¡å‹å¯¹æ¯”" class="headerlink" title="æ¨¡å‹å¯¹æ¯”"></a>æ¨¡å‹å¯¹æ¯”</h2><ol>
<li><h3 id="LR-vs-SVM"><a href="#LR-vs-SVM" class="headerlink" title="LR vs SVM"></a>LR vs SVM</h3><ul>
<li><p>ä¸åŒ</p>
<ul>
<li>LRçš„æŸå¤±å‡½æ•°æ˜¯Cross entropy lossï¼ŒSVMçš„æŸå¤±å‡½æ•°æ˜¯Hinge lossï¼Œè‡ªå¸¦L2æ­£åˆ™</li>
<li>LRçš„è§£æ˜¯å—æ•°æ®æœ¬èº«åˆ†å¸ƒå½±å“çš„ï¼Œè€ŒSVMçš„è§£ä¸å—æ•°æ®åˆ†å¸ƒçš„å½±å“ï¼ˆæ”¯æŒå‘é‡ï¼‰</li>
<li>LRçš„è¾“å‡ºå…·æœ‰è‡ªç„¶çš„æ¦‚ç‡æ„ä¹‰ï¼Œè€ŒSVMçš„è¾“å‡ºä¸å…·æœ‰æ¦‚ç‡æ„ä¹‰</li>
<li>SVMä¾èµ–æ•°æ®è¡¨è¾¾çš„è·ç¦»æµ‹åº¦ï¼Œéœ€è¦å¯¹æ•°æ®normalizationï¼ŒLRåˆ™ä¸éœ€è¦</li>
<li>SVMå—æƒ©ç½šç³»æ•°Cçš„å½±å“è¾ƒå¤§ï¼Œå®éªŒä¸­éœ€è¦åšValidationï¼ŒLRåˆ™ä¸éœ€è¦</li>
<li>LRé€‚åˆäºå¤§æ ·æœ¬å­¦ä¹ ï¼ŒSVMé€‚åˆäºå°æ ·æœ¬å­¦ä¹  ï¼Ÿï¼Ÿï¼Ÿ</li>
<li>SVMå¯ä»¥å¤„ç†å¤§å‹ç‰¹å¾ç©ºé—´ï¼ŒLRå¯¹æ­¤æ€§èƒ½ä¸å¥½ ï¼Ÿï¼Ÿï¼Ÿ</li>
<li><a href="https://shomy.top/2017/03/09/support-vector-regression/" target="_blank" rel="noopener">SVM å›å½’</a> </li>
</ul>
</li>
<li><p>ç›¸åŒ</p>
<ul>
<li>çº¿æ€§å†³ç­–</li>
<li>kernel trickï¼Œker-SVMåªéœ€è¦è®¡ç®—æ”¯æŒå‘é‡çš„æ ¸å‡½æ•°ï¼›è€Œ<a href="https://shomy.top/2017/03/07/kernel-lr/" target="_blank" rel="noopener">ker-LR</a>éœ€è¦æ‰€æœ‰çš„æ ·æœ¬ ï¼Ÿï¼Ÿï¼Ÿ</li>
<li>éƒ½ä¼šå—åˆ°outlierçš„å½±å“</li>
</ul>
<p>åªæœ‰å°†æœ€ä¼˜è§£wè¡¨ç¤ºä¸ºxiçš„çº¿æ€§ç»„åˆï¼Œæ‰èƒ½å¤Ÿåˆ©ç”¨æ ¸å‡½æ•°K<br>å¦‚æœæ ·æœ¬æ•°é‡å°äºç‰¹å¾æ•°ï¼Œé‚£ä¹ˆå°±æ²¡å¿…è¦é€‰æ‹©éçº¿æ€§æ ¸ï¼Œç®€å•çš„ä½¿ç”¨çº¿æ€§æ ¸å°±å¯ä»¥äº†<br>å¦‚æœæ ·æœ¬æ•°é‡å¤§äºç‰¹å¾æ•°ç›®ï¼Œè¿™æ—¶å¯ä»¥ä½¿ç”¨éçº¿æ€§æ ¸ï¼Œå°†æ ·æœ¬æ˜ å°„åˆ°æ›´é«˜ç»´åº¦ï¼Œä¸€èˆ¬å¯ä»¥å¾—åˆ°æ›´å¥½çš„ç»“æœ</p>
<p><a href="https://shomy.top/archives/page/2/" target="_blank" rel="noopener">https://shomy.top/archives/page/2/</a></p>
</li>
</ul>
</li>
<li><h3 id="LR-vs-å†³ç­–æ ‘"><a href="#LR-vs-å†³ç­–æ ‘" class="headerlink" title="LR vs å†³ç­–æ ‘"></a>LR vs å†³ç­–æ ‘</h3><ul>
<li>å†³ç­–æ ‘å¯ä»¥å¤„ç†ç¼ºå¤±å€¼ï¼ŒLRä¸å¯ä»¥</li>
<li>LRçº¿æ€§å†³ç­–è¾¹ç•Œï¼Œå¯èƒ½æ¬ æ‹Ÿåˆï¼ˆä½†æ˜¯å¯ä»¥æ ¸æ–¹æ³•ï¼‰ï¼Œå†³ç­–æ ‘éçº¿æ€§å†³ç­–è¾¹ç•Œï¼Œä½†æ˜¯å¯¹çº¿æ€§æ‹Ÿåˆæ•ˆæœå®¹æ˜“è¿‡æ‹Ÿåˆã€‚ï¼ˆå¦‚ï¼›x+y=1ï¼‰ï¼ˆä½†æ˜¯å¯ä»¥å‰ªæï¼Œæ­£åˆ™ï¼Œbaggingï¼‰</li>
<li>LRæœ‰æ¦‚ç‡å€¼è§£é‡Šï¼Œå†³ç­–æ ‘æœ‰å†³ç­–è¿‡ç¨‹ç›´è§‚è§£é‡Š</li>
<li>LRå¯¹æ•°æ®æ•´ä½“ç»“æ„çš„åˆ†æä¼˜äºå†³ç­–æ ‘ï¼Œè€Œå†³ç­–æ ‘å¯¹å±€éƒ¨ç»“æ„çš„åˆ†æä¼˜äºLRã€‚</li>
<li>LRå¯¹æå€¼æ¯”è¾ƒæ•æ„Ÿï¼Œå®¹æ˜“å—æç«¯å€¼çš„å½±å“</li>
<li>å†³ç­–æ ‘å®¹æ˜“è¿‡æ‹Ÿåˆï¼›</li>
<li>GDBT + LR èåˆ</li>
</ul>
</li>
<li><h3 id="RF-vs-GDBT"><a href="#RF-vs-GDBT" class="headerlink" title="RF vs GDBT"></a>RF vs GDBT</h3><ul>
<li>ä¸åŒ<ul>
<li>ç»„æˆéšæœºæ£®æ—çš„æ ‘å¯ä»¥å¹¶è¡Œç”Ÿæˆï¼Œè€ŒGBDTæ˜¯ä¸²è¡Œç”Ÿæˆ</li>
<li>éšæœºæ£®æ—çš„ç»“æœæ˜¯å¤šæ•°è¡¨å†³è¡¨å†³çš„ï¼Œè€ŒGBDTåˆ™æ˜¯å¤šæ£µæ ‘ç´¯åŠ ä¹‹å’Œ</li>
<li>éšæœºæ£®æ—å¯¹å¼‚å¸¸å€¼ä¸æ•æ„Ÿï¼Œè€ŒGBDTå¯¹å¼‚å¸¸å€¼æ¯”è¾ƒæ•æ„Ÿ</li>
<li>éšæœºæ£®æ—æ˜¯é€šè¿‡å‡å°‘æ¨¡å‹çš„æ–¹å·®æ¥æé«˜æ€§èƒ½ï¼Œè€ŒGBDTæ˜¯å‡å°‘æ¨¡å‹çš„åå·®æ¥æé«˜æ€§èƒ½çš„</li>
<li>éšæœºæ£®æ—ä¸éœ€è¦è¿›è¡Œæ•°æ®é¢„å¤„ç†ï¼Œå³ç‰¹å¾å½’ä¸€åŒ–ã€‚GBDTåˆ™éœ€è¦è¿›è¡Œç‰¹å¾å½’ä¸€åŒ– ï¼Ÿï¼Ÿï¼Ÿä¸ºä»€ä¹ˆè¦å½’ä¸€åŒ–</li>
<li>ç»„æˆéšæœºæ£®æ—çš„æ ‘å¯ä»¥åˆ†ç±»æ ‘ä¹Ÿå¯ä»¥æ˜¯å›å½’æ ‘ï¼ŒGBDTç”±cartæ ‘ç»„æˆ</li>
</ul>
</li>
<li>ç›¸åŒ<ul>
<li>é›†æˆç®—æ³•</li>
</ul>
</li>
</ul>
</li>
<li><h3 id="XgBoost-vs-GBDT"><a href="#XgBoost-vs-GBDT" class="headerlink" title="XgBoost vs GBDT"></a>XgBoost vs GBDT</h3></li>
</ol>
<p><a href="https://zhuanlan.zhihu.com/p/46831267" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/46831267</a><br><a href="https://zhuanlan.zhihu.com/p/34679467" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/34679467</a></p>
]]></content>
      <categories>
        <category>ML</category>
      </categories>
      <tags>
        <tag>æœºå™¨å­¦ä¹ </tag>
        <tag>ML</tag>
      </tags>
  </entry>
  <entry>
    <title>Transformerè¯¦è§£ï¼šå„ä¸ªç‰¹å¾ç»´åº¦åˆ†ææ¨å¯¼</title>
    <url>/transformer/</url>
    <content><![CDATA[<p>è°·æ­Œåœ¨æ–‡ç« ã€ŠAttention is all you needã€‹ä¸­æå‡ºçš„transformeræ¨¡å‹ã€‚å¦‚å›¾ä¸»è¦æ¶æ„ï¼šåŒæ ·ä¸ºencoder-decoderæ¨¡å¼ï¼Œå·¦è¾¹éƒ¨åˆ†æ˜¯encoderï¼Œå³è¾¹éƒ¨åˆ†æ˜¯decoderã€‚<br>TensorFlowä»£ç ï¼š<em><a href="https://www.github.com/kyubyong/transformer" target="_blank" rel="noopener">https://www.github.com/kyubyong/transformer</a></em><br><img src="/images/transformer1.png" alt=""></p>
<a id="more"></a>

<h1 id="é¢„å¤„ç†"><a href="#é¢„å¤„ç†" class="headerlink" title="é¢„å¤„ç†"></a>é¢„å¤„ç†</h1><p>ç”¨ sentencepiece è¿›è¡Œåˆ†è¯ã€‚</p>
<h1 id="Encoder-è¾“å…¥"><a href="#Encoder-è¾“å…¥" class="headerlink" title="Encoder è¾“å…¥"></a>Encoder è¾“å…¥</h1><p>åˆå§‹è¾“å…¥ä¸ºå¾…ç¿»è¯‘è¯­å¥çš„embeddingçŸ©é˜µï¼Œç”±äºå¥å­é•¿åº¦ä¸ä¸€è‡´ï¼Œéœ€è¦åšç»Ÿä¸€é•¿åº¦å¤„ç†ï¼Œé•¿åº¦å–maxlength1ï¼Œä¸å¤Ÿé•¿çš„å¥å­padding 0å€¼ï¼Œå¥å°¾åŠ ä¸Š <code>&lt;/s&gt;</code> ã€‚</p>
<pre><code>d = 512, [batchsizeï¼Œmaxlen1ï¼Œd]</code></pre><p>è€ƒè™‘åˆ°è¯è¯­é—´çš„ç›¸å¯¹ä½ç½®ä¿¡æ¯ï¼Œè¿˜è¦åŠ ä¸Šè¯­å¥çš„position<br>encodingï¼Œç”±å‡½æ•°å½¢å¼ç›´æ¥æ±‚å‡ºã€‚</p>
<pre><code>PE(pos,2i) = sin(pos/10002i/d)
PE(pos,2i+1) = cos(pos/10002i/d)</code></pre><p>Paddingçš„å€¼ä¸åšposition encodingã€‚ <code>[batchsizeï¼Œmaxlen1ï¼Œd]</code> ï¼Œæœ€ç»ˆ:</p>
<pre><code>encoder input = position encoding + input embeddingã€‚
encoder input : [batchsizeï¼Œmaxlen1ï¼Œd]</code></pre><h1 id="Encoder"><a href="#Encoder" class="headerlink" title="Encoder"></a>Encoder</h1><p>Encoder ç”±N = 6ä¸ªç›¸åŒçš„layerè¿æ¥ç»„æˆã€‚æ¯ä¸ªlayerä¸­æœ‰ä¸¤ä¸ªsublayerï¼Œåˆ†åˆ«æ˜¯multihead<br>self-attentionä»¥åŠFFNã€‚</p>
<pre><code>Q = K = V = input
MultiHead(Q, K, V) = concat(head1, â€¦, headh)Wo
headi = Attention(QWÂ­iQï¼ŒKWÂ­ikï¼ŒVWÂ­iV)
Attention(Q, K, V) = softmax(QKT/$$\sqrt{d}$$) V</code></pre><p><img src="/images/transformer1.png" alt=""><br><img src="/images/transformer3.png" alt=""><br><img src="/images/transformer4.png" alt=""></p>
<p>softmaxå‰è¦åškey_maskï¼ŒæŠŠpad 0 çš„åœ°æ–¹èµ‹å€¼ä¸º-infï¼Œsoftmaxåæƒé‡åšquery maskï¼Œèµ‹å€¼0ã€‚</p>
<pre><code>h = 8
WÂ­iQ, WÂ­ik, WÂ­iV : [d, d/h]
Q : [maxlen_q, d]
K = V : [maxlen_k, d]
Maxlen_q = maxlen_k so: Q = K = V : [maxlen1, d]
QWÂ­kQï¼ŒKWÂ­ikï¼ŒVWÂ­iV : [maxlen1, d/h]
headi : [maxlen1, d/h] \* [d/h, maxlen1] \* [maxlen1, d/h] = [maxlen1, d/h]
Wo : [d, d]
MultiHead(Q,K,V): [maxlen, d]</code></pre><p><code>Softmax([maxlen_q, maxlen_k])</code> åœ¨æœ€åä¸€ä¸ªç»´åº¦å³ <code>maxlen_k</code> ä¸Šåš <code>softmax</code>ã€‚<br>position-wiseæ˜¯å› ä¸ºå¤„ç†çš„attentionè¾“å‡ºæ˜¯æŸä¸€ä¸ªä½ç½®içš„attentionè¾“å‡ºã€‚</p>
<pre><code>FFN(x) = ReLU ( xW1 + b1 ) \* W2 + b2
ReLU(x) = max( 0, x )
dff = 4 \* d = 2048
W1 : [d, dff]
W2 : [dff, d]</code></pre><p>æµç¨‹ï¼š</p>
<pre><code>Input -&gt; dropout -&gt;
(
multihead self-attention -&gt; dropout -&gt; residual connection -&gt; LN -&gt;
FFN-&gt; dropout -&gt; residual connection -&gt; LN -&gt;
) * 6
-&gt; memory [batchsizeï¼Œmaxlenï¼Œd]</code></pre><p>ä»£ç ä¸­åœ¨multihead attentionä¸­å¯¹scoreåšdropoutï¼ŒFFNåæ²¡æœ‰dropoutï¼Œä½†æ–‡ç« è¯´æ¯ä¸ªsublayerçš„outputéƒ½æœ‰ä¸€ä¸ªdropoutã€‚</p>
<h1 id="Decoder-è¾“å…¥"><a href="#Decoder-è¾“å…¥" class="headerlink" title="Decoder è¾“å…¥"></a>Decoder è¾“å…¥</h1><h2 id="è®­ç»ƒ"><a href="#è®­ç»ƒ" class="headerlink" title="è®­ç»ƒ"></a>è®­ç»ƒ</h2><p>ç›®æ ‡å¥å­é¦–å°¾åˆ†åˆ«åŠ ä¸Š <code>&lt;s&gt;</code> , <code>&lt;/s&gt;</code>ã€‚</p>
<pre><code>Decoder input = Output embedding + position encoding
Decoder input : [batchsizeï¼Œmaxlen2ï¼Œd]</code></pre><h2 id="é¢„æµ‹"><a href="#é¢„æµ‹" class="headerlink" title="é¢„æµ‹"></a>é¢„æµ‹</h2><p>åˆå§‹å‘é‡ä¸º<code>&lt;s&gt;</code>å¯¹åº”embeddingï¼Œä¹‹åå°†å‰ä¸€æ­¥çš„è¾“å‡ºæ‹¼æ¥åˆ°å½“å‰çš„æ‰€æœ‰é¢„æµ‹æ„æˆå½“å‰çš„decoderè¾“å…¥ã€‚</p>
<h2 id="Decoder"><a href="#Decoder" class="headerlink" title="Decoder"></a>Decoder</h2><p>Decoderç”±N = 6 ä¸ªç›¸åŒçš„layerç»„æˆï¼Œæ¯ä¸ªlayerä¸­æœ‰ä¸‰ä¸ªsublayerï¼Œåˆ†åˆ«æ˜¯multihead self-attention, mutihead attentionä»¥åŠFFNã€‚</p>
<pre><code>decoder input -&gt; dropout -&gt;
(
   Masked multihead self-attention(dec, dec, dec) = dec-&gt; dropout -&gt;
   multihead attention(dec, memory, memory) -&gt; dropout -&gt; residual connection
   -&gt; LN -&gt; FFN -&gt; dropout -&gt; residual connection -&gt; LN -&gt;
) * 6
-&gt; dec -&gt; linear -&gt; softmax</code></pre><p>Self-attention çš„maskä¸ºä¸€ä¸ªå’Œdecç›¸åŒç»´åº¦çš„ä¸Šä¸‰è§’å…¨ä¸º-infçš„çŸ©é˜µã€‚</p>
<pre><code>Linear( x ) = xW
Dec : [batchsizeï¼Œmaxlen2ï¼Œd]
W : [d, vocabsize]</code></pre><p>Wä¸ºè¯æ±‡è¡¨embeddingçŸ©é˜µçš„è½¬ç½®, è¾“å…¥è¾“å‡ºçš„è¯æ±‡è¡¨embeddingçŸ©é˜µä¸ºWã€‚å³ä¸‰ä¸ªå‚æ•°å…±äº«ã€‚</p>
<pre><code>Linear( x ) : [batchsizeï¼Œmaxlen2ï¼Œvocabsize]</code></pre><p>Softmaxå‡½æ•°ï¼š</p>
<center>
$p\left( k\|x \right)=\frac{\exp({{z}_{k}})}{\sum\nolimits_{i=1}^{K}{\exp ({{z}_{i}})}}$
</center>
å…¶ä¸­ziä¸€èˆ¬å«åš logitsï¼Œå³æœªè¢«å½’ä¸€åŒ–çš„å¯¹æ•°æ¦‚ç‡ã€‚

<h1 id="æŸå¤±å‡½æ•°"><a href="#æŸå¤±å‡½æ•°" class="headerlink" title="æŸå¤±å‡½æ•°"></a>æŸå¤±å‡½æ•°</h1><p>æŸå¤±å‡½æ•°ï¼šcross entropyã€‚ç”¨pä»£è¡¨predicted probabilityï¼Œç”¨qä»£è¡¨groundtruthã€‚å³ï¼š</p>
<center>$cross\_entropy\_loss=\sum\limits_{k=1}^{K}{q\left( k\|x\right)\log (p\left( k\|x \right))}$</center>


<p>groundtruthä¸ºone-hotï¼Œå³æ¯ä¸ªæ ·æœ¬åªæœ‰æƒŸä¸€çš„ç±»åˆ«ï¼Œ$q(k)={{\delta}_{k,y}}$ï¼Œyæ˜¯çœŸå®ç±»åˆ«ã€‚</p>
<center>${{\delta }_{k,y}}\text{=}\left\{\begin{matrix} 1,k=y \\0,k\ne y \\\end{matrix} \right.$</center>


<p>å¯¹ç›®æ ‡å¥å­onehot åšlabelmsmoothç”¨$\tilde{q}(k|x)$ä»£æ›¿$q(k|x)$ã€‚ï¼ˆä¸ºäº†æ­£åˆ™åŒ–ï¼Œé˜²æ­¢è¿‡æ‹Ÿåˆï¼‰</p>
<center>$\tilde{q}(k\|x)=(1-\varepsilon ){{\delta }_{k,y}}+\varepsilon u(k)$</center>


<p>å¯ä»¥ç†è§£ä¸ºï¼Œå¯¹äº$q(k)={{\delta}_{k,y}}$å‡½æ•°åˆ†å¸ƒçš„çœŸå®æ ‡ç­¾ï¼Œå°†å®ƒå˜æˆä»¥å¦‚ä¸‹æ–¹å¼è·å¾—ï¼šé¦–å…ˆä»æ ‡æ³¨çš„çœŸå®æ ‡ç­¾çš„$\delta$åˆ†å¸ƒä¸­å–å®šï¼Œç„¶åä»¥ä¸€å®šçš„æ¦‚ç‡$\varepsilon$ï¼Œå°†å…¶æ›¿æ¢ä¸ºåœ¨$u(k)$åˆ†å¸ƒä¸­çš„éšæœºå˜é‡ã€‚$u(k)$ä¸ºå‡åŒ€åˆ†å¸ƒï¼Œå³$u(k)=1/K$</p>
<h1 id="ä¼˜åŒ–æ–¹æ³•"><a href="#ä¼˜åŒ–æ–¹æ³•" class="headerlink" title="ä¼˜åŒ–æ–¹æ³•"></a>ä¼˜åŒ–æ–¹æ³•</h1><p>Adamä¼˜åŒ–å™¨ï¼š<br><img src="/images/transformer5.png" alt=""><br>å­¦ä¹ ç‡ä½¿ç”¨warm up learning rate:</p>
<pre><code>learningrate = dmodel-0.5 \* min ( step_num-0.5, step_num \* warmup_steps-1.5 )
warmup_steps ï¼š4000</code></pre>]]></content>
      <categories>
        <category>NLP</category>
      </categories>
      <tags>
        <tag>transoformer</tag>
      </tags>
  </entry>
  <entry>
    <title>MarkDown ä½¿ç”¨ç»†èŠ‚</title>
    <url>/markdown/</url>
    <content><![CDATA[<p>è®°å½•ä½¿ç”¨é‡åˆ°çš„ä¸€äº›å¸¸ç”¨çš„MarkDownå‘½ä»¤</p>
<a id="more"></a>

<p>è¡Œå†…æ ‡ç­¾</p>
<pre><code>`&lt;ä½ çš„ GitHub ç”¨æˆ·å&gt;.github.io`</code></pre><p>æ–‡å­—å±…ä¸­</p>
<pre><code>&lt;center&gt;æ–‡å­—    &lt;/center&gt;</code></pre>]]></content>
      <categories>
        <category>blog</category>
      </categories>
      <tags>
        <tag>markdown</tag>
      </tags>
  </entry>
  <entry>
    <title>å¸¸ç”¨å¥æ³•åˆ†æå·¥å…·åŒ…ä½¿ç”¨è¯´æ˜ï¼šHanlpã€StanfordNLPç­‰</title>
    <url>/parser/</url>
    <content><![CDATA[<p>å¯¹æ¯”å„ä¸ªå¸¸ç”¨çš„è‡ªç„¶è¯­è¨€å¤„ç†å·¥å…·åŒ…ä¸­çš„å¥æ³•åˆ†ææ¨¡å—ã€‚</p>
<a id="more"></a>

<h1 id="Hanlp"><a href="#Hanlp" class="headerlink" title="Hanlp"></a>Hanlp</h1><p>pip install pyhanlp å®‰è£…å³å¯<br>é¡¹ç›®åœ°å€ï¼š<a href="https://github.com/hankcs/pyhanlp" target="_blank" rel="noopener">https://github.com/hankcs/pyhanlp</a></p>
<p><strong>åŸºäºç¥ç»ç½‘ç»œçš„é«˜æ€§èƒ½ä¾å­˜å¥æ³•åˆ†æå™¨</strong></p>
<p>è¾“å‡ºä¸ºCONLLæ ¼å¼ä¸­ï¼Œæ¯ä¸ªè¯è¯­å ä¸€è¡Œï¼Œæ— å€¼åˆ—ç”¨ä¸‹åˆ’çº¿ä»£æ›¿ï¼Œåˆ—çš„åˆ†éš”ç¬¦ä¸ºåˆ¶è¡¨ç¬¦ <code>&#39;\t&#39;</code> ï¼Œè¡Œçš„åˆ†éš”ç¬¦ä¸ºæ¢è¡Œç¬¦ <code>&#39;\n&#39;</code>ï¼›å¥å­ä¸å¥å­ä¹‹é—´ç”¨ç©ºè¡Œåˆ†éš”ã€‚<br>CONLLæ ‡æ³¨æ ¼å¼åŒ…å«10åˆ—ï¼Œåˆ†åˆ«ä¸ºï¼š  </p>
<table>
<thead>
<tr>
<th align="center">ID</th>
<th align="center">FORM</th>
<th align="center">LEMMA</th>
<th align="center">CPOSTAG</th>
<th align="center">POSTAG</th>
<th align="center">FEATS</th>
<th align="center">HEAD</th>
<th align="center">DEPREL</th>
<th align="center">PHEAD</th>
<th align="center">PDEPREL</th>
</tr>
</thead>
</table>
<p>åªç”¨åˆ°å‰ï¼˜åˆ—ï¼Œå…¶å«ä¹‰åˆ†åˆ«ä¸ºï¼š  </p>
<table>
<thead>
<tr>
<th align="center">id</th>
<th align="center">name</th>
<th align="center">å«ä¹‰</th>
</tr>
</thead>
<tbody><tr>
<td align="center">1</td>
<td align="center">ID</td>
<td align="center">å½“å‰è¯åœ¨å¥å­ä¸­çš„åºå·ï¼Œï¼‘å¼€å§‹.</td>
</tr>
<tr>
<td align="center">2</td>
<td align="center">FORM</td>
<td align="center">å½“å‰è¯è¯­æˆ–æ ‡ç‚¹</td>
</tr>
<tr>
<td align="center">3</td>
<td align="center">LEMMA</td>
<td align="center">å½“å‰è¯è¯­ï¼ˆæˆ–æ ‡ç‚¹ï¼‰çš„åŸå‹æˆ–è¯å¹²ï¼Œåœ¨ä¸­æ–‡ä¸­ï¼Œæ­¤åˆ—ä¸FORMç›¸åŒ</td>
</tr>
<tr>
<td align="center">4</td>
<td align="center">CPOSTAG</td>
<td align="center">å½“å‰è¯è¯­çš„è¯æ€§ï¼ˆç²—ç²’åº¦ï¼‰</td>
</tr>
<tr>
<td align="center">5</td>
<td align="center">POSTAG</td>
<td align="center">å½“å‰è¯è¯­çš„è¯æ€§ï¼ˆç»†ç²’åº¦ï¼‰</td>
</tr>
<tr>
<td align="center">6</td>
<td align="center">FEATS</td>
<td align="center">å¥æ³•ç‰¹å¾ï¼Œåœ¨æœ¬æ¬¡è¯„æµ‹ä¸­ï¼Œæ­¤åˆ—æœªè¢«ä½¿ç”¨ï¼Œå…¨éƒ¨ä»¥ä¸‹åˆ’çº¿ä»£æ›¿ã€‚</td>
</tr>
<tr>
<td align="center">7</td>
<td align="center">HEAD</td>
<td align="center">å½“å‰è¯è¯­çš„ä¸­å¿ƒè¯</td>
</tr>
<tr>
<td align="center">8</td>
<td align="center">DEPREL</td>
<td align="center">å½“å‰è¯è¯­ä¸ä¸­å¿ƒè¯çš„ä¾å­˜å…³ç³»</td>
</tr>
</tbody></table>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> pyhanlp <span class="keyword">import</span> *</span></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">print(HanLP.parseDependency(<span class="string">"å¾å…ˆç”Ÿè¿˜å…·ä½“å¸®åŠ©ä»–ç¡®å®šäº†æŠŠç”»é›„é¹°ã€æ¾é¼ å’Œéº»é›€ä½œä¸ºä¸»æ”»ç›®æ ‡ã€‚"</span>))</span></pre></td></tr></table></figure>

<pre><code>1    å¾å…ˆç”Ÿ    å¾å…ˆç”Ÿ    nh    nr    _    4    ä¸»è°“å…³ç³»    _    _
2    è¿˜    è¿˜    d    d    _    4    çŠ¶ä¸­ç»“æ„    _    _
3    å…·ä½“    å…·ä½“    a    ad    _    4    çŠ¶ä¸­ç»“æ„    _    _
4    å¸®åŠ©    å¸®åŠ©    v    v    _    0    æ ¸å¿ƒå…³ç³»    _    _
5    ä»–    ä»–    r    r    _    4    å…¼è¯­    _    _
6    ç¡®å®š    ç¡®å®š    v    v    _    4    åŠ¨å®¾å…³ç³»    _    _
7    äº†    äº†    u    u    _    6    å³é™„åŠ å…³ç³»    _    _
8    æŠŠ    æŠŠ    p    p    _    15    çŠ¶ä¸­ç»“æ„    _    _
9    ç”»    ç”»    v    v    _    8    ä»‹å®¾å…³ç³»    _    _
10    é›„é¹°    é›„é¹°    n    n    _    9    åŠ¨å®¾å…³ç³»    _    _
11    ã€    ã€    wp    w    _    12    æ ‡ç‚¹ç¬¦å·    _    _
12    æ¾é¼     æ¾é¼     n    n    _    10    å¹¶åˆ—å…³ç³»    _    _
13    å’Œ    å’Œ    c    c    _    14    å·¦é™„åŠ å…³ç³»    _    _
14    éº»é›€    éº»é›€    n    n    _    10    å¹¶åˆ—å…³ç³»    _    _
15    ä½œä¸º    ä½œä¸º    v    v    _    6    åŠ¨å®¾å…³ç³»    _    _
16    ä¸»æ”»    ä¸»æ”»    v    vn    _    17    å®šä¸­å…³ç³»    _    _
17    ç›®æ ‡    ç›®æ ‡    n    n    _    15    åŠ¨å®¾å…³ç³»    _    _
18    ã€‚    ã€‚    wp    w    _    4    æ ‡ç‚¹ç¬¦å·    _    _</code></pre><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">sentence = HanLP.parseDependency(<span class="string">"å¾å…ˆç”Ÿè¿˜å…·ä½“å¸®åŠ©ä»–ç¡®å®šäº†æŠŠç”»é›„é¹°ã€æ¾é¼ å’Œéº»é›€ä½œä¸ºä¸»æ”»ç›®æ ‡ã€‚"</span>)</span></pre></td></tr><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> word <span class="keyword">in</span> sentence.iterator():  <span class="comment"># é€šè¿‡dir()å¯ä»¥æŸ¥çœ‹sentenceçš„æ–¹æ³•</span></span></pre></td></tr><tr><td class="code"><pre><span class="line">    print(<span class="string">"%s --(%s)--&gt; %s"</span> % (word.LEMMA, word.DEPREL, word.HEAD.LEMMA))</span></pre></td></tr></table></figure>

<pre><code>å¾å…ˆç”Ÿ --(ä¸»è°“å…³ç³»)--&gt; å¸®åŠ©
è¿˜ --(çŠ¶ä¸­ç»“æ„)--&gt; å¸®åŠ©
å…·ä½“ --(çŠ¶ä¸­ç»“æ„)--&gt; å¸®åŠ©
å¸®åŠ© --(æ ¸å¿ƒå…³ç³»)--&gt; ##æ ¸å¿ƒ##
ä»– --(å…¼è¯­)--&gt; å¸®åŠ©
ç¡®å®š --(åŠ¨å®¾å…³ç³»)--&gt; å¸®åŠ©
äº† --(å³é™„åŠ å…³ç³»)--&gt; ç¡®å®š
æŠŠ --(çŠ¶ä¸­ç»“æ„)--&gt; ä½œä¸º
ç”» --(ä»‹å®¾å…³ç³»)--&gt; æŠŠ
é›„é¹° --(åŠ¨å®¾å…³ç³»)--&gt; ç”»
ã€ --(æ ‡ç‚¹ç¬¦å·)--&gt; æ¾é¼ 
æ¾é¼  --(å¹¶åˆ—å…³ç³»)--&gt; é›„é¹°
å’Œ --(å·¦é™„åŠ å…³ç³»)--&gt; éº»é›€
éº»é›€ --(å¹¶åˆ—å…³ç³»)--&gt; é›„é¹°
ä½œä¸º --(åŠ¨å®¾å…³ç³»)--&gt; ç¡®å®š
ä¸»æ”» --(å®šä¸­å…³ç³»)--&gt; ç›®æ ‡
ç›®æ ‡ --(åŠ¨å®¾å…³ç³»)--&gt; ä½œä¸º
ã€‚ --(æ ‡ç‚¹ç¬¦å·)--&gt; å¸®åŠ©</code></pre><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">print(dir(sentence))</span></pre></td></tr></table></figure>

<pre><code>[&apos;__class__&apos;, &apos;__delattr__&apos;, &apos;__dict__&apos;, &apos;__dir__&apos;, &apos;__doc__&apos;, &apos;__eq__&apos;, &apos;__format__&apos;, &apos;__ge__&apos;, &apos;__getattribute__&apos;, &apos;__gt__&apos;, &apos;__hash__&apos;, &apos;__init__&apos;, &apos;__init_subclass__&apos;, &apos;__javaclass__&apos;, &apos;__javaobject__&apos;, &apos;__le__&apos;, &apos;__lt__&apos;, &apos;__metaclass__&apos;, &apos;__module__&apos;, &apos;__ne__&apos;, &apos;__new__&apos;, &apos;__reduce__&apos;, &apos;__reduce_ex__&apos;, &apos;__repr__&apos;, &apos;__setattr__&apos;, &apos;__sizeof__&apos;, &apos;__str__&apos;, &apos;__subclasshook__&apos;, &apos;__weakref__&apos;, &apos;edgeArray&apos;, &apos;equals&apos;, &apos;findChildren&apos;, &apos;forEach&apos;, &apos;getClass&apos;, &apos;getEdgeArray&apos;, &apos;getWordArray&apos;, &apos;getWordArrayWithRoot&apos;, &apos;hashCode&apos;, &apos;iterator&apos;, &apos;notify&apos;, &apos;notifyAll&apos;, &apos;spliterator&apos;, &apos;toString&apos;, &apos;wait&apos;, &apos;word&apos;, &apos;wordArray&apos;, &apos;wordArrayWithRoot&apos;]</code></pre><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">word_array = sentence.getWordArray()</span></pre></td></tr><tr><td class="code"><pre><span class="line"><span class="comment"># print(word_array[0])</span></span></pre></td></tr><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> word <span class="keyword">in</span> word_array:</span></pre></td></tr><tr><td class="code"><pre><span class="line">    print(<span class="string">"%s --(%s)--&gt; %s"</span> % (word.LEMMA, word.DEPREL, word.HEAD.LEMMA))</span></pre></td></tr></table></figure>

<pre><code>å¾å…ˆç”Ÿ --(ä¸»è°“å…³ç³»)--&gt; å¸®åŠ©
è¿˜ --(çŠ¶ä¸­ç»“æ„)--&gt; å¸®åŠ©
å…·ä½“ --(çŠ¶ä¸­ç»“æ„)--&gt; å¸®åŠ©
å¸®åŠ© --(æ ¸å¿ƒå…³ç³»)--&gt; ##æ ¸å¿ƒ##
ä»– --(å…¼è¯­)--&gt; å¸®åŠ©
ç¡®å®š --(åŠ¨å®¾å…³ç³»)--&gt; å¸®åŠ©
äº† --(å³é™„åŠ å…³ç³»)--&gt; ç¡®å®š
æŠŠ --(çŠ¶ä¸­ç»“æ„)--&gt; ä½œä¸º
ç”» --(ä»‹å®¾å…³ç³»)--&gt; æŠŠ
é›„é¹° --(åŠ¨å®¾å…³ç³»)--&gt; ç”»
ã€ --(æ ‡ç‚¹ç¬¦å·)--&gt; æ¾é¼ 
æ¾é¼  --(å¹¶åˆ—å…³ç³»)--&gt; é›„é¹°
å’Œ --(å·¦é™„åŠ å…³ç³»)--&gt; éº»é›€
éº»é›€ --(å¹¶åˆ—å…³ç³»)--&gt; é›„é¹°
ä½œä¸º --(åŠ¨å®¾å…³ç³»)--&gt; ç¡®å®š
ä¸»æ”» --(å®šä¸­å…³ç³»)--&gt; ç›®æ ‡
ç›®æ ‡ --(åŠ¨å®¾å…³ç³»)--&gt; ä½œä¸º
ã€‚ --(æ ‡ç‚¹ç¬¦å·)--&gt; å¸®åŠ©</code></pre><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># è¿˜å¯ä»¥ç›´æ¥éå†å­æ ‘ï¼Œä»æŸæ£µå­æ ‘çš„æŸä¸ªèŠ‚ç‚¹ä¸€è·¯éå†åˆ°è™šæ ¹</span></span></pre></td></tr><tr><td class="code"><pre><span class="line">CoNLLWord = JClass(<span class="string">"com.hankcs.hanlp.corpus.dependency.CoNll.CoNLLWord"</span>)</span></pre></td></tr><tr><td class="code"><pre><span class="line">head = word_array[<span class="number">15</span>]</span></pre></td></tr><tr><td class="code"><pre><span class="line"><span class="keyword">while</span> head.HEAD:</span></pre></td></tr><tr><td class="code"><pre><span class="line">    head = head.HEAD</span></pre></td></tr><tr><td class="code"><pre><span class="line">    <span class="keyword">if</span> (head == CoNLLWord.ROOT):</span></pre></td></tr><tr><td class="code"><pre><span class="line">        print(head.LEMMA)</span></pre></td></tr><tr><td class="code"><pre><span class="line">    <span class="keyword">else</span>:</span></pre></td></tr><tr><td class="code"><pre><span class="line">        print(<span class="string">"%s --(%s)--&gt; "</span> % (head.LEMMA, head.DEPREL))</span></pre></td></tr></table></figure>

<pre><code>ç›®æ ‡ --(åŠ¨å®¾å…³ç³»)--&gt; 
ä½œä¸º --(åŠ¨å®¾å…³ç³»)--&gt; 
ç¡®å®š --(åŠ¨å®¾å…³ç³»)--&gt; 
å¸®åŠ© --(æ ¸å¿ƒå…³ç³»)--&gt; 
##æ ¸å¿ƒ##</code></pre><h1 id="StanfordNLP"><a href="#StanfordNLP" class="headerlink" title="StanfordNLP"></a>StanfordNLP</h1><p>pip install stanfordnlp å®‰è£…å³å¯<br>é¡¹ç›®åœ°å€ï¼š<a href="https://github.com/stanfordnlp/stanfordnlp" target="_blank" rel="noopener">https://github.com/stanfordnlp/stanfordnlp</a><br>ä¾å­˜å¥æ³•å…³ç³»ç¬¦å·è§£é‡Šï¼š<a href="https://www.cnblogs.com/sherry-yang/p/9061341.html" target="_blank" rel="noopener">https://www.cnblogs.com/sherry-yang/p/9061341.html</a></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> stanfordnlp</span></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">nlp = stanfordnlp.Pipeline(lang=<span class="string">'zh'</span>)</span></pre></td></tr></table></figure>

<pre><code>Use device: gpu
---
Loading: tokenize
With settings: 
{&apos;model_path&apos;: &apos;/home/haha/stanfordnlp_resources/zh_gsd_models/zh_gsd_tokenizer.pt&apos;, &apos;lang&apos;: &apos;zh&apos;, &apos;shorthand&apos;: &apos;zh_gsd&apos;, &apos;mode&apos;: &apos;predict&apos;}
---
Loading: pos
With settings: 
{&apos;model_path&apos;: &apos;/home/haha/stanfordnlp_resources/zh_gsd_models/zh_gsd_tagger.pt&apos;, &apos;pretrain_path&apos;: &apos;/home/haha/stanfordnlp_resources/zh_gsd_models/zh_gsd.pretrain.pt&apos;, &apos;lang&apos;: &apos;zh&apos;, &apos;shorthand&apos;: &apos;zh_gsd&apos;, &apos;mode&apos;: &apos;predict&apos;}
---
Loading: lemma
With settings: 
{&apos;model_path&apos;: &apos;/home/haha/stanfordnlp_resources/zh_gsd_models/zh_gsd_lemmatizer.pt&apos;, &apos;lang&apos;: &apos;zh&apos;, &apos;shorthand&apos;: &apos;zh_gsd&apos;, &apos;mode&apos;: &apos;predict&apos;}
Building an attentional Seq2Seq model...
Using a Bi-LSTM encoder
Using soft attention for LSTM.
Finetune all embeddings.
[Running seq2seq lemmatizer with edit classifier]
---
Loading: depparse
With settings: 
{&apos;model_path&apos;: &apos;/home/haha/stanfordnlp_resources/zh_gsd_models/zh_gsd_parser.pt&apos;, &apos;pretrain_path&apos;: &apos;/home/haha/stanfordnlp_resources/zh_gsd_models/zh_gsd.pretrain.pt&apos;, &apos;lang&apos;: &apos;zh&apos;, &apos;shorthand&apos;: &apos;zh_gsd&apos;, &apos;mode&apos;: &apos;predict&apos;}
Done loading processors!
---</code></pre><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">doc = nlp(<span class="string">"å¾å…ˆç”Ÿè¿˜å…·ä½“å¸®åŠ©ä»–ç¡®å®šäº†æŠŠç”»é›„é¹°ã€æ¾é¼ å’Œéº»é›€ä½œä¸ºä¸»æ”»ç›®æ ‡ã€‚"</span>)</span></pre></td></tr><tr><td class="code"><pre><span class="line">doc.sentences[<span class="number">0</span>].print_dependencies()</span></pre></td></tr></table></figure>

<pre><code>(&apos;å¾&apos;, &apos;2&apos;, &apos;nmod&apos;)
(&apos;å…ˆç”Ÿ&apos;, &apos;4&apos;, &apos;nsubj&apos;)
(&apos;è¿˜&apos;, &apos;4&apos;, &apos;mark&apos;)
(&apos;å…·ä½“&apos;, &apos;0&apos;, &apos;root&apos;)
(&apos;å¸®åŠ©&apos;, &apos;4&apos;, &apos;obj&apos;)
(&apos;ä»–&apos;, &apos;7&apos;, &apos;nsubj&apos;)
(&apos;ç¡®å®š&apos;, &apos;4&apos;, &apos;ccomp&apos;)
(&apos;äº†&apos;, &apos;7&apos;, &apos;case:aspect&apos;)
(&apos;æŠŠ&apos;, &apos;15&apos;, &apos;aux:caus&apos;)
(&apos;ç”»é›„é¹°&apos;, &apos;15&apos;, &apos;obj&apos;)
(&apos;ã€&apos;, &apos;12&apos;, &apos;punct&apos;)
(&apos;æ¾é¼ &apos;, &apos;10&apos;, &apos;conj&apos;)
(&apos;å’Œ&apos;, &apos;14&apos;, &apos;cc&apos;)
(&apos;éº»é›€&apos;, &apos;10&apos;, &apos;conj&apos;)
(&apos;ä½œ&apos;, &apos;7&apos;, &apos;ccomp&apos;)
(&apos;ä¸º&apos;, &apos;15&apos;, &apos;mark&apos;)
(&apos;ä¸»æ”»&apos;, &apos;18&apos;, &apos;nmod&apos;)
(&apos;ç›®æ ‡&apos;, &apos;16&apos;, &apos;obj&apos;)
(&apos;ã€‚&apos;, &apos;4&apos;, &apos;punct&apos;)</code></pre><h1 id="HIT-LTP"><a href="#HIT-LTP" class="headerlink" title="HIT LTP"></a>HIT LTP</h1><p>é¡¹ç›®åœ°å€ï¼š  </p>
<ul>
<li><a href="https://github.com/HIT-SCIR/pyltp" target="_blank" rel="noopener">https://github.com/HIT-SCIR/pyltp</a>  </li>
<li><a href="https://pyltp.readthedocs.io/zh_CN/latest/" target="_blank" rel="noopener">https://pyltp.readthedocs.io/zh_CN/latest/</a>  </li>
</ul>
<p>å®‰è£…æ­¥éª¤ï¼š</p>
<ul>
<li>pip install pyltp</li>
<li>ä¸‹è½½æ¨¡å‹æ–‡ä»¶ï¼š<a href="http://ltp.ai/download.html" target="_blank" rel="noopener">ä¸ƒç‰›äº‘</a>ï¼Œå½“å‰æ¨¡å‹ç‰ˆæœ¬ 3.4.0</li>
</ul>
<p>è¾“å‡ºï¼š</p>
<ul>
<li>arc.head è¡¨ç¤ºä¾å­˜å¼§çš„çˆ¶èŠ‚ç‚¹è¯çš„ç´¢å¼•ã€‚ROOTèŠ‚ç‚¹çš„ç´¢å¼•æ˜¯0ï¼Œç¬¬ä¸€ä¸ªè¯å¼€å§‹çš„ç´¢å¼•ä¾æ¬¡ä¸º1ã€2ã€3â€¦  </li>
<li>arc.relation è¡¨ç¤ºä¾å­˜å¼§çš„å…³ç³»ã€‚  </li>
</ul>
<p>æ ‡æ³¨é›†è¯·å‚è€ƒ: <a href="https://ltp.readthedocs.io/zh_CN/latest/appendix.html#id5" target="_blank" rel="noopener">https://ltp.readthedocs.io/zh_CN/latest/appendix.html#id5</a></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> pyltp <span class="keyword">import</span> Parser</span></pre></td></tr><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> pyltp <span class="keyword">import</span> Segmentor</span></pre></td></tr><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> pyltp <span class="keyword">import</span> Postagger</span></pre></td></tr><tr><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">dependency_parser</span><span class="params">(sentences)</span>:</span></span></pre></td></tr><tr><td class="code"><pre><span class="line">    output = []</span></pre></td></tr><tr><td class="code"><pre><span class="line">    <span class="keyword">for</span> sentence <span class="keyword">in</span> sentences:</span></pre></td></tr><tr><td class="code"><pre><span class="line">        parser = Parser()</span></pre></td></tr><tr><td class="code"><pre><span class="line">        parser.load(<span class="string">'./ltp_data_v3.4.0/parser.model'</span>)</span></pre></td></tr><tr><td class="code"><pre><span class="line">        segmentor = Segmentor() </span></pre></td></tr><tr><td class="code"><pre><span class="line">        segmentor.load(<span class="string">'./ltp_data_v3.4.0/cws.model'</span>)</span></pre></td></tr><tr><td class="code"><pre><span class="line">        postagger = Postagger() </span></pre></td></tr><tr><td class="code"><pre><span class="line">        postagger.load(<span class="string">'./ltp_data_v3.4.0/pos.model'</span>)</span></pre></td></tr><tr><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="code"><pre><span class="line">        words = segmentor.segment(sentence)</span></pre></td></tr><tr><td class="code"><pre><span class="line">        postags = postagger.postag(words)</span></pre></td></tr><tr><td class="code"><pre><span class="line">        arcs = parser.parse(words, postags)</span></pre></td></tr><tr><td class="code"><pre><span class="line">        output.append(&#123;<span class="string">'words'</span>:words,</span></pre></td></tr><tr><td class="code"><pre><span class="line">                       <span class="string">'postags'</span>:postags,</span></pre></td></tr><tr><td class="code"><pre><span class="line">                       <span class="string">'arcs'</span>:arcs</span></pre></td></tr><tr><td class="code"><pre><span class="line">                      &#125;)</span></pre></td></tr><tr><td class="code"><pre><span class="line"><span class="comment">#         print(' '.join(output[0]['words']))</span></span></pre></td></tr><tr><td class="code"><pre><span class="line"><span class="comment">#         print(' '.join(output[0]['postags']))</span></span></pre></td></tr><tr><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="code"><pre><span class="line">    segmentor.release() </span></pre></td></tr><tr><td class="code"><pre><span class="line">    postagger.release()</span></pre></td></tr><tr><td class="code"><pre><span class="line">    parser.release()</span></pre></td></tr><tr><td class="code"><pre><span class="line">    <span class="keyword">return</span> output</span></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">sentences = [<span class="string">'å¾å…ˆç”Ÿè¿˜å…·ä½“å¸®åŠ©ä»–ç¡®å®šäº†æŠŠç”»é›„é¹°ï¼Œæ¾é¼ å’Œéº»é›€ä½œä¸ºä¸»æ”»ç›®æ ‡ã€‚'</span>]</span></pre></td></tr><tr><td class="code"><pre><span class="line">output = dependency_parser(sentences)</span></pre></td></tr><tr><td class="code"><pre><span class="line">Arcs = [each[<span class="string">'arcs'</span>] <span class="keyword">for</span> each <span class="keyword">in</span> output]</span></pre></td></tr><tr><td class="code"><pre><span class="line">[<span class="string">" "</span>.join(<span class="string">"%d:%s"</span> % (arc.head, arc.relation) <span class="keyword">for</span> arc <span class="keyword">in</span> arcs) <span class="keyword">for</span> arcs <span class="keyword">in</span> Arcs]</span></pre></td></tr></table></figure>




<pre><code>[&apos;2:ATT 5:SBV 4:ADV 5:ADV 0:HED 5:DBL 5:VOB 7:RAD 10:ADV 7:VOB 10:VOB 5:WP 16:SBV 15:LAD 13:COO 5:COO 18:ATT 16:VOB 5:WP&apos;]</code></pre><h1 id="FudanNLP-FNLP"><a href="#FudanNLP-FNLP" class="headerlink" title="FudanNLP (FNLP)"></a>FudanNLP (FNLP)</h1><p><a href="https://github.com/FudanNLP/fnlp" target="_blank" rel="noopener">https://github.com/FudanNLP/fnlp</a><br>java æ¥å£ï¼Œä¸”ä¸å†æ›´æ–°ï¼Œç°åœ¨å·²ç»æ¨å‡ºFastNLP</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="code"><pre><span class="line"></span></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>NLP</category>
      </categories>
      <tags>
        <tag>parser</tag>
      </tags>
  </entry>
  <entry>
    <title>SQuAD2.0 åˆ·æ¦œtop3æ¨¡å‹åˆ†æ</title>
    <url>/SQuAD2-0/</url>
    <content><![CDATA[<p>ç”±äº<a href="https://rajpurkar.github.io/SQuAD-explorer/" target="_blank" rel="noopener">SQuAD2.0æ¦œå•</a>ä¸€ç›´åœ¨æ›´æ–°ï¼Œæ‰€ä»¥top3æ¨¡å‹ä¹Ÿåœ¨æ›´æ–°ã€‚</p>
<a id="more"></a>
<h2 id="top1-BERT-DAE-AoA"><a href="#top1-BERT-DAE-AoA" class="headerlink" title="top1: BERT + DAE + AoA"></a>top1: BERT + DAE + AoA</h2><ul>
<li>AoA: attention over attention [1]</li>
<li>DAE: DA Enhanced<ul>
<li>Data Augmentation</li>
<li>Domain Adaptation<br><img src="/images/aoa.png" alt="AoA"></li>
</ul>
</li>
</ul>
<p><a href="https://www.infoq.cn/article/M7NpCAAMrPzRo-RViOKs" target="_blank" rel="noopener">https://www.infoq.cn/article/M7NpCAAMrPzRo-RViOKs</a><br><a href="https://zhuanlan.zhihu.com/p/27361305" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/27361305</a></p>
<pre><code>[1] Cui Y, Chen Z, Wei S, et al. Attention-over-attention neural networks for reading comprehension[J]. arXiv preprint arXiv:1607.04423, 2016.</code></pre><h2 id="top2-BERT-ConvLSTM-MTL-Verifier"><a href="#top2-BERT-ConvLSTM-MTL-Verifier" class="headerlink" title="top2: BERT + ConvLSTM + MTL + Verifier"></a>top2: BERT + ConvLSTM + MTL + Verifier</h2><ul>
<li>MTL: å¤šä»»åŠ¡å­¦ä¹ <ul>
<li><del>é¢„æµ‹ä¸€ä¸ªé—®é¢˜æ˜¯å¦å¯ç­”</del></li>
<li><del>é¢„æµ‹è¯¥é—®é¢˜åœ¨ç¯‡ç« ä¸­çš„ç­”æ¡ˆ</del></li>
</ul>
</li>
<li>Verifier: éªŒè¯å™¨ [1]</li>
<li>convLSTM [2]</li>
</ul>
<p><a href="https://msd.misuland.com/pd/12136984602514128" target="_blank" rel="noopener">https://msd.misuland.com/pd/12136984602514128</a><br><a href="https://blog.csdn.net/maka_uir/article/details/83650978" target="_blank" rel="noopener">https://blog.csdn.net/maka_uir/article/details/83650978</a></p>
<pre><code>[1] Hu M, Peng Y, Huang Z, et al. Read+ verify: Machine reading comprehension with unanswerable questions[J]. arXiv preprint arXiv:1808.05759, 2018.
[2] Shi X , Chen Z , Wang H , et al. Convolutional LSTM Network: A Machine Learning Approach for Precipitation Nowcasting[J]. 2015.</code></pre><h2 id="top3-BERT-N-Gram-Masking-Synthetic-Self-Training"><a href="#top3-BERT-N-Gram-Masking-Synthetic-Self-Training" class="headerlink" title="top3: BERT + N-Gram Masking + Synthetic Self-Training"></a>top3: BERT + N-Gram Masking + Synthetic Self-Training</h2><ul>
<li>N-Gram Masking: ç±»ä¼¼ç™¾åº¦çš„ERNIEæ¨¡å‹</li>
<li>Synthetic Self-Training: BERTå®˜æ–¹PPT  </li>
</ul>
<p>(è¿™ä¸ªæ–¹æ³•å…¨éƒ¨åœ¨é¢„è®­ç»ƒä¸Šåšæ”¹è¿›ï¼Œæ²¡æœ‰å¯¹bertä¸Šå±‚æ¨¡å‹åšä»€ä¹ˆæ”¹è¿›)<br>Unclear if adding things on top of BERT really helps by very much.  </p>
<p><a href="https://zhuanlan.zhihu.com/p/63126803" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/63126803</a><br><a href="https://nlp.stanford.edu/seminar/details/jdevlin.pdf" target="_blank" rel="noopener">https://nlp.stanford.edu/seminar/details/jdevlin.pdf</a></p>
<h2 id="å…¶ä»–"><a href="#å…¶ä»–" class="headerlink" title="å…¶ä»–"></a>å…¶ä»–</h2><p><a href="http://web.stanford.edu/class/cs224n/posters/15845024.pdf" target="_blank" rel="noopener">http://web.stanford.edu/class/cs224n/posters/15845024.pdf</a></p>
<pre><code>[1] Ensemble BERT with Data Augmentation and Linguistic Knowledge on SQuAD2.0</code></pre>]]></content>
      <categories>
        <category>NLP</category>
      </categories>
      <tags>
        <tag>SQuAD2.0</tag>
      </tags>
  </entry>
  <entry>
    <title>GitHub Pages + Hexo + Nextï¼šåšå®¢æ­å»ºã€åŠŸèƒ½è®¾ç½®åŠç¾åŒ–</title>
    <url>/next/</url>
    <content><![CDATA[<p>ä½¿ç”¨Hexoåšå®¢æ¡†æ¶æ­å»ºè‡ªå·±çš„ä¸ªäººåšå®¢ï¼Œå¹¶éƒ¨ç½²åˆ°ä¸ªäººçš„GitHubä¸Šï¼Œé€‰ç”¨NexTä¸»é¢˜ï¼Œæ·»åŠ ä¸€äº›ä½¿ç”¨å°åŠŸèƒ½å¹¶è¿›è¡Œç•Œé¢çš„ç¾åŒ–ã€‚</p>
<a id="more"></a>

<h1 id="Hexo"><a href="#Hexo" class="headerlink" title="Hexo"></a>Hexo</h1><p>Hexo æ˜¯ä¸€ä¸ªå¿«é€Ÿã€ç®€æ´ä¸”é«˜æ•ˆçš„åšå®¢æ¡†æ¶ã€‚Hexo ä½¿ç”¨ Markdownï¼ˆæˆ–å…¶ä»–æ¸²æŸ“å¼•æ“ï¼‰è§£ææ–‡ç« ï¼Œåœ¨å‡ ç§’å†…ï¼Œå³å¯åˆ©ç”¨é“ä¸½çš„ä¸»é¢˜ç”Ÿæˆé™æ€ç½‘é¡µã€‚</p>
<h2 id="æ­å»ºåšå®¢æ¡†æ¶"><a href="#æ­å»ºåšå®¢æ¡†æ¶" class="headerlink" title="æ­å»ºåšå®¢æ¡†æ¶"></a>æ­å»ºåšå®¢æ¡†æ¶</h2><p>æ­å»ºæµç¨‹å‚ç…§å®˜ç½‘ä¸­æ–‡è¯´æ˜æ–‡æ¡£ï¼š</p>
<pre><code>https://hexo.io/zh-cn/docs/</code></pre><h2 id="éƒ¨ç½²"><a href="#éƒ¨ç½²" class="headerlink" title="éƒ¨ç½²"></a>éƒ¨ç½²</h2><p>å°†æ­å»ºåœ¨æœ¬åœ°çš„åšå®¢é€šè¿‡GitHub Pageséƒ¨ç½²åœ¨ä¸ªäººçš„GitHubä¸­ã€‚ä»è€Œèƒ½é€šè¿‡ <code>&lt;ä½ çš„ GitHub ç”¨æˆ·å&gt;.github.io</code> åŸŸåè®¿é—®åšå®¢</p>
<p>å‚è€ƒæ•™ç¨‹ï¼š</p>
<pre><code>https://www.jianshu.com/p/05289a4bc8b2
https://www.cnblogs.com/jackyroc/p/7681938.html</code></pre><h1 id="Next-ä¸»é¢˜"><a href="#Next-ä¸»é¢˜" class="headerlink" title="Next ä¸»é¢˜"></a>Next ä¸»é¢˜</h1><p>éƒ¨ç½²å®Œæˆåï¼Œå³å¯å¯¹åšå®¢åšä¸€äº›ç»†èŠ‚ä¸Šçš„ä¼˜åŒ–ï¼Œå¢æ·»å°å·¥å…·ä»¥åŠç¾åŒ–ç•Œé¢</p>
<p>å‚è€ƒæ•™ç¨‹ï¼š</p>
<pre><code>https://zhuanlan.zhihu.com/p/30836436
https://io-oi.me/tech/hexo-next-optimization/</code></pre><h2 id="å­—ä½“è°ƒèŠ‚"><a href="#å­—ä½“è°ƒèŠ‚" class="headerlink" title="å­—ä½“è°ƒèŠ‚"></a>å­—ä½“è°ƒèŠ‚</h2><p>Nextä¸»é¢˜é»˜è®¤å­—ä½“ä¸º <code>font-size-medium = 1em</code> ï¼Œæœ‰ç‚¹å¤§ã€‚é€šå¸¸æ¥è®²ï¼ŒNextä¸»é¢˜æ§åˆ¶å­—ä½“å¤§å°çš„æ–‡ä»¶æ˜¯åœ¨ä¸»é¢˜æ–‡ä»¶å¤¹ä¸­çš„ <code>source\css_variables</code> ç›®å½•ä¸‹çš„ <code>base.styl</code> æ–‡ä»¶ä¸­ï¼Œä¿®æ”¹å¦‚ä¸‹æ–‡ä»¶ ï¼š</p>
<pre><code>// Font size
$font-size-base           = (hexo-config(&apos;font.enable&apos;) and hexo-config(&apos;font.global.size&apos;) is a &apos;unit&apos;) ? unit(hexo-config(&apos;font.global.size&apos;), em) : 1em;
$font-size-smallest       = .75em;
$font-size-smaller        = .8125em;
$font-size-small          = .875em;
$font-size-medium         = 1em;
$font-size-large          = 1.125em;
$font-size-larger         = 1.25em;
$font-size-largest        = 1.375em;</code></pre><p>æŠŠ <code>1em</code> æ”¹ä¸º <code>0.875em</code> å³å¯:</p>
<pre><code>// Font size
$font-size-base           = (hexo-config(&apos;font.enable&apos;) and hexo-config(&apos;font.global.size&apos;) is a &apos;unit&apos;) ? unit(hexo-config(&apos;font.global.size&apos;), em) : .875em;
$font-size-smallest       = .75em;
$font-size-smaller        = .8125em;
$font-size-small          = .875em;
$font-size-medium         = 1em;
$font-size-large          = 1.125em;
$font-size-larger         = 1.25em;
$font-size-largest        = 1.375em;</code></pre><h2 id="æ’å…¥æœ¬åœ°å›¾ç‰‡"><a href="#æ’å…¥æœ¬åœ°å›¾ç‰‡" class="headerlink" title="æ’å…¥æœ¬åœ°å›¾ç‰‡"></a>æ’å…¥æœ¬åœ°å›¾ç‰‡</h2><p>èµ„æºï¼ˆAssetï¼‰ä»£è¡¨ source æ–‡ä»¶å¤¹ä¸­é™¤äº†æ–‡ç« ä»¥å¤–çš„æ‰€æœ‰æ–‡ä»¶ï¼Œä¾‹å¦‚å›¾ç‰‡ã€CSSã€JS æ–‡ä»¶ç­‰ã€‚æ¯”æ–¹è¯´ï¼Œå¦‚æœä½ çš„Hexoé¡¹ç›®ä¸­åªæœ‰å°‘é‡å›¾ç‰‡ï¼Œé‚£æœ€ç®€å•çš„æ–¹æ³•å°±æ˜¯å°†å®ƒä»¬æ”¾åœ¨ <code>source/images</code> æ–‡ä»¶å¤¹ä¸­ã€‚ç„¶åé€šè¿‡ç±»ä¼¼äº <code>![](/images/image.jpg)</code> çš„æ–¹æ³•è®¿é—®å®ƒä»¬ã€‚</p>
<h2 id="æ·»åŠ â¤è„šæ³¨"><a href="#æ·»åŠ â¤è„šæ³¨" class="headerlink" title="æ·»åŠ â¤è„šæ³¨"></a>æ·»åŠ â¤è„šæ³¨</h2><p>æ›´æ”¹ä¸»é¢˜é…ç½®æ–‡ä»¶ï¼š</p>
<pre><code>icon:
  # Icon name in Font Awesome. See: https://fontawesome.com/v4.7.0/icons/
  # `heart` is recommended with animation in red (#ff0000).
  name: heart #user
  # If you want to animate the icon, set it to true.
  animated: true
  # Change the color of icon, using Hex Code.
  # color: &quot;#808080&quot;
  color: &quot;#ff0000&quot;</code></pre><h2 id="æœç´¢å¼•æ“ä¼˜åŒ–"><a href="#æœç´¢å¼•æ“ä¼˜åŒ–" class="headerlink" title="æœç´¢å¼•æ“ä¼˜åŒ–"></a>æœç´¢å¼•æ“ä¼˜åŒ–</h2><h3 id="æ ‡é¢˜ä¼˜åŒ–"><a href="#æ ‡é¢˜ä¼˜åŒ–" class="headerlink" title="æ ‡é¢˜ä¼˜åŒ–"></a>æ ‡é¢˜ä¼˜åŒ–</h3><p>ç»™æ ‡é¢˜å¢åŠ è¯¦ç»†ä¿¡æ¯,æ›´æ”¹ <code>index.swig</code> æ–‡ä»¶ <code>your-hexo-site\themes\next\layout</code>: </p>
<pre><code>{% block title %}{{ title }}{%- if theme.index_with_subtitle and subtitle %} - {{ subtitle }}{%- endif %}{% endblock %}

	{% block title %}{{ title }}{%- if theme.index_with_subtitle and subtitle %} - {{ subtitle }}{%- endif %} - {{ theme.keywords }} - {{ config.title }}{{ theme.description }}{% endblock %}</code></pre><h3 id="ä¿®æ”¹é“¾æ¥"><a href="#ä¿®æ”¹é“¾æ¥" class="headerlink" title="ä¿®æ”¹é“¾æ¥"></a>ä¿®æ”¹é“¾æ¥</h3><p>HEXOé»˜è®¤çš„æ–‡ç« é“¾æ¥å½¢å¼ä¸º <code>domain/year/month/day/postname</code> ï¼Œé»˜è®¤å°±æ˜¯ä¸€ä¸ªå››çº§urlï¼Œå¹¶ä¸”å¯èƒ½é€ æˆurlè¿‡é•¿ï¼Œå¯¹æœç´¢å¼•æ“æ˜¯ååˆ†ä¸å‹å¥½çš„ï¼Œæˆ‘ä»¬å¯ä»¥æ”¹æˆ <code>domain/postname</code> çš„å½¢å¼ã€‚ç¼–è¾‘ç«™ç‚¹ <code>_config.yml</code> æ–‡ä»¶ï¼Œä¿®æ”¹å…¶ä¸­çš„ <code>permalink</code> å­—æ®µæ”¹ä¸º <code>permalink: :title.html</code> å³å¯ã€‚</p>
<pre><code>permalink: :year/:month/:day/:title/
permalink: :title/</code></pre><p>å‚è€ƒ:</p>
<pre><code>http://www.ehcoo.com/seo.html</code></pre><h2 id="é¦–é¡µé˜…è¯»å…¨æ–‡è®¾ç½®"><a href="#é¦–é¡µé˜…è¯»å…¨æ–‡è®¾ç½®" class="headerlink" title="é¦–é¡µé˜…è¯»å…¨æ–‡è®¾ç½®"></a>é¦–é¡µé˜…è¯»å…¨æ–‡è®¾ç½®</h2><ol>
<li>åœ¨æ–‡ç« ä¸­æ‰‹åŠ¨åŠ å…¥ <code>&lt;!--more--&gt;</code> è¿›è¡Œæˆªæ–­</li>
<li>é€šè¿‡åœ¨é…ç½®æ–‡ä»¶ä¸­åŠ å…¥ä»£ç ï¼Œè‡ªåŠ¨æˆªæ–­ï¼ˆä½†å®éªŒå¤±è´¥ï¼‰ã€‚</li>
</ol>
<h2 id="å­—æ•°ç»Ÿè®¡åŠé˜…è¯»æ—¶é•¿"><a href="#å­—æ•°ç»Ÿè®¡åŠé˜…è¯»æ—¶é•¿" class="headerlink" title="å­—æ•°ç»Ÿè®¡åŠé˜…è¯»æ—¶é•¿"></a>å­—æ•°ç»Ÿè®¡åŠé˜…è¯»æ—¶é•¿</h2><p>å®‰è£… <code>hexo-wordcount</code> å¤±è´¥åé‡‡ç”¨ä¸‹é¢æ–¹æ³•ï¼š</p>
<pre><code>npm install hexo-symbols-count-time --save</code></pre><p>åœ¨é…ç½®æ–‡ä»¶åŠ å…¥è®¾ç½®ï¼š</p>
<pre><code>symbols_count_time:  
  symbols: true  
  time: true  
  total_symbols: true  
  total_time: true</code></pre><h2 id="é˜…è¯»æ¬¡æ•°ç»Ÿè®¡"><a href="#é˜…è¯»æ¬¡æ•°ç»Ÿè®¡" class="headerlink" title="é˜…è¯»æ¬¡æ•°ç»Ÿè®¡"></a>é˜…è¯»æ¬¡æ•°ç»Ÿè®¡</h2><p>ä¸»é¢˜é…ç½®æ–‡ä»¶è®¾ç½®ï¼š</p>
<pre><code>busuanzi_count:
  enable: true
  total_visitors: true
  total_visitors_icon: user
  total_views: true
  total_views_icon: eye
  post_views: true
  post_views_icon: eye</code></pre><h2 id="è¯„è®ºåŠŸèƒ½"><a href="#è¯„è®ºåŠŸèƒ½" class="headerlink" title="è¯„è®ºåŠŸèƒ½"></a>è¯„è®ºåŠŸèƒ½</h2><p>Nextä¸»é¢˜å·²ç»é›†æˆäº†GitTalk,ç›´æ¥ä½¿ç”¨å³å¯ã€‚é¦–å…ˆï¼Œæ³¨å†ŒGitHub OAuth Appsï¼Œç”Ÿæˆ<code>client_id</code> å’Œ <code>client_secret</code> ã€‚å†ä¿®æ”¹ä¸»é¢˜é…ç½®æ–‡ä»¶ï¼š</p>
<pre><code>gitalk:
  enable: true
  github_id: troublemeeter # GitHub repo owner
  repo: troublemeeter.github.io # Repository name to store issues
  client_id: # GitHub Application Client ID
  client_secret: # GitHub Application Client Secret
  admin_user: troublemeeter # GitHub repo owner and collaborators, only these guys can initialize gitHub issues
  distraction_free_mode: true # Facebook-like distraction free mode
  # Gitalk&apos;s display language depends on user&apos;s browser or system environment
  # If you want everyone visiting your site to see a uniform language, you can set a force language value
  # Available values: en | es-ES | fr | ru | zh-CN | zh-TW
  language:</code></pre><p>å‚è€ƒæ•™ç¨‹ï¼š</p>
<pre><code>https://mrluyc.github.io/2019/07/30/HexoNexT%E9%9B%86%E6%88%90Gitalk/</code></pre><h2 id="æ•°å­¦å…¬å¼æ”¯æŒ"><a href="#æ•°å­¦å…¬å¼æ”¯æŒ" class="headerlink" title="æ•°å­¦å…¬å¼æ”¯æŒ"></a>æ•°å­¦å…¬å¼æ”¯æŒ</h2><p>å®‰è£… <code>hexo-math</code>ï¼š</p>
<pre><code>$ npm install hexo-math --save</code></pre><p>åœ¨é…ç½®æ–‡ä»¶åŠ å…¥è®¾ç½®ï¼š</p>
<pre><code>math:
  engine: &apos;mathjax&apos; # or &apos;katex&apos;
  mathjax:
    # src: custom_mathjax_source
    config:
      # MathJax config</code></pre><p>åœ¨Nextä¸»é¢˜é…ç½®æ–‡ä»¶æ›´æ”¹è®¾ç½®ä¸ºï¼š</p>
<pre><code># Math Formulas Render Support
math:
  # Default (true) will load mathjax / katex script on demand.
  # That is it only render those page which has `mathjax: true` in Front-matter.
  # If you set it to false, it will load mathjax / katex srcipt EVERY PAGE.
  per_page: true
  # hexo-renderer-pandoc (or hexo-renderer-kramed) required for full MathJax support.
  mathjax:
    enable: true
    # See: https://mhchem.github.io/MathJax-mhchem/
    mhchem: false</code></pre><p>åœ¨éœ€è¦åŠ è½½mathjaxçš„æ–‡ä»¶çš„å¤´éƒ¨åŠ å…¥<code>mathjax: true</code>ï¼š</p>
<pre><code>---
title: transformer
date: 2019-12-10 17:50:42
tags:
mathjax: true
---</code></pre><h2 id="ä»£ç é«˜äº®"><a href="#ä»£ç é«˜äº®" class="headerlink" title="ä»£ç é«˜äº®"></a>ä»£ç é«˜äº®</h2><p>ä¸å–œæ¬¢äº”é¢œå…­è‰²ï¼Œæ‰€ä»¥æš‚æ—¶æœªå¤„ç†ã€‚</p>
<h2 id="æ‰“èµåŠŸèƒ½"><a href="#æ‰“èµåŠŸèƒ½" class="headerlink" title="æ‰“èµåŠŸèƒ½"></a>æ‰“èµåŠŸèƒ½</h2><p>åˆ¶ä½œå¥½å¾®ä¿¡æ”¶æ¬¾ç å’Œæ”¯ä»˜å®æ”¶æ¬¾ç ï¼Œä¿å­˜è‡³<code>themes/next/source/images</code>ã€‚å¹¶ä¿®æ”¹ä¸»é¢˜é…ç½®æ–‡ä»¶å¦‚ä¸‹ï¼š</p>
<pre><code># Reward (Donate)
# Front-matter variable (unsupport animation).
reward_settings:
  # If true, reward will be displayed in every article by default.
  enable: true
  animation: true
  comment: ğŸ¤£~ç–¯ç‹‚æš—ç¤º~ğŸ¤£</code></pre><p>æ•ˆæœå¦‚ä¸‹ï¼Œä¸ä¿¡è¯•ä¸€è¯•~</p>
]]></content>
      <categories>
        <category>blog</category>
      </categories>
      <tags>
        <tag>hexo</tag>
        <tag>next</tag>
      </tags>
  </entry>
</search>
